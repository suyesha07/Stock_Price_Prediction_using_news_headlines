{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SP using news headline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPop5qxsqpE/0F5ETJeIHom",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyesha07/Stock_Price_Prediction_using_news_headlines/blob/main/SP_using_news_headline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Q2T9v6Kn7Vh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from textblob import TextBlob\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analize_sentiment(tweet):\n",
        "    \n",
        "    analysis = TextBlob((str(tweet)))     #defining the function which will find the plority of a sentence\n",
        "    return analysis.polarity \n"
      ],
      "metadata": {
        "id": "gHS-z2vIuO9Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news= pd.read_csv('Combined_News_DJIA.csv')\n",
        "\n",
        "train_news = news[news['Date'] < '2014-07-15']   # SPLITTING THE DATASET INTO TRAINING AND TESTING\n",
        "test_news = news[news['Date'] > '2014-07-14']\n",
        "\n",
        "train_news_list = []\n",
        "for row in range(0,len(train_news.index)): # CONVERT THE TRAINNG DATASET OF 27 COLUMNS INTO ONE ELEMENT IN THE LIST FOR EACH DAY\n",
        "    train_news_list.append(' '.join(str(k) for k in train_news.iloc[row,2:27]))\n",
        "    "
      ],
      "metadata": {
        "id": "GL43_M4punIo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize= CountVectorizer(min_df=0.01, max_df=0.8) # DEFINING THE VECTOR FUNCTION, SPECIFYING THR MIN AND MAX WORD FREQUENCY FILTER\n",
        "news_vector = vectorize.fit_transform(train_news_list) # TRANSFORMING THE TRAINING DATASET INTO WORD FREQUENCY TRANFORMATION\n",
        "print( \"THE TABLE OF FREQUENCY WORD DISTRIBUTION\" , news_vector.shape)\n",
        "\n",
        "lr=LogisticRegression()\n",
        "model = lr.fit(news_vector, train_news[\"Label\"])\n",
        "\n",
        "test_news_list = []\n",
        "for row in range(0,len(test_news.index)):\n",
        "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:27]))# CONVERT THE TESTING DATASET OF 27 COLUMNS INTO ONE ELEMENT IN THE LIST FOR EACH DAY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTCA_wILvMeQ",
        "outputId": "af87f899-4fe0-43b9-c3d3-9abc040ae055"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE TABLE OF FREQUENCY WORD DISTRIBUTION (1492, 4733)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_vector = vectorize.transform(test_news_list) # TRANSFORMING THE TESTING DATASET INTO WORD FREQUENCY TRANFORMATION\n",
        "\n",
        "predictions = model.predict(test_vector)\n",
        "\n",
        "pd.crosstab(test_news[\"Label\"], predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
        "\n",
        "accuracy1=accuracy_score(test_news['Label'], predictions)\n",
        "print(\"the baseline model accuracy\", accuracy1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx22tjfrvVr2",
        "outputId": "ac3ba1d3-3286-40a6-bab1-7041de3311ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the baseline model accuracy 0.4607645875251509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = vectorize.get_feature_names()\n",
        "coefficients = model.coef_.tolist()[0]\n",
        "coeffdf = pd.DataFrame({'Word' : words,'Coefficient' : coefficients})  # WORD DISTRIBUTION OF THE MODEL\n",
        "\n",
        "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
        "print(\"Top ten words according to the baseline model\",coeffdf.head(10))\n",
        "print(\"Last ten words according to the baseline model\",coeffdf.tail(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdfrpuI9vceT",
        "outputId": "99372a2d-3bad-41d6-a9c2-4d3660a749a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top ten words according to the baseline model           Word  Coefficient\n",
            "3728      self     0.628003\n",
            "4647      wing     0.532282\n",
            "2090  hospital     0.532009\n",
            "2392     kills     0.524826\n",
            "284      among     0.516879\n",
            "4387      turn     0.515314\n",
            "762     cartel     0.513590\n",
            "2929  olympics     0.509167\n",
            "1146  damascus     0.505753\n",
            "3585      rise     0.503551\n",
            "Last ten words according to the baseline model            Word  Coefficient\n",
            "3770        sex    -0.540544\n",
            "1163         de    -0.541079\n",
            "990       congo    -0.548451\n",
            "4206     terror    -0.555603\n",
            "4047   students    -0.563997\n",
            "3653  sanctions    -0.569230\n",
            "2100      hours    -0.572524\n",
            "506       begin    -0.602589\n",
            "4301      total    -0.610891\n",
            "3626        run    -0.665577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-gram"
      ],
      "metadata": {
        "id": "kx3ByuEkBt8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nvectorize = TfidfVectorizer(min_df=0.05, max_df=0.85,ngram_range=(2,2)) # DEFINING THE TFID TRANSFORMATION FUNCTION\n",
        "news_nvector = nvectorize.fit_transform(train_news_list)\n",
        "\n",
        "print(\" TFID TRANSFOMATION DATAFRAME SHAPE\",news_nvector.shape)\n",
        "\n",
        "nmodel = lr.fit(news_nvector, train_news[\"Label\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asl3rbeNvnvF",
        "outputId": "65113438-3f49-44be-ebd0-c99816beec3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TFID TRANSFOMATION DATAFRAME SHAPE (1492, 284)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_news_list = []\n",
        "for row in range(0,len(test_news.index)):\n",
        "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:27])) # CONVERT THE TESTING DATASET OF 27 COLUMNS INTO ONE ELEMENT IN THE LIST FOR EACH DAY\n",
        "ntest_vector = nvectorize.transform(test_news_list)\n",
        "npredictions = nmodel.predict(ntest_vector)\n",
        "\n",
        "pd.crosstab(test_news[\"Label\"], npredictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
        "\n",
        "accuracy2=accuracy_score(test_news['Label'], npredictions)\n",
        "print(\" Logistics Regression with Bigram and TFID\",accuracy2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WArZqDRRvumg",
        "outputId": "0cabb05f-4717-4971-eda2-1cdacc94f018"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Logistics Regression with Bigram and TFID 0.5311871227364185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nwords = nvectorize.get_feature_names()\n",
        "ncoefficients = nmodel.coef_.tolist()[0]\n",
        "ncoeffdf = pd.DataFrame({'Word' : nwords, \n",
        "                        'Coefficient' : ncoefficients})\n",
        "ncoeffdf = ncoeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
        "ncoeffdf.head(10)\n",
        "ncoeffdf.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "HrFcccJSv09W",
        "outputId": "200aa618-820f-4487-f1f1-2d579c7d499e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Word  Coefficient\n",
              "242       to help    -0.870909\n",
              "262        us and    -0.880771\n",
              "4      accused of    -0.952199\n",
              "153    people are    -0.974838\n",
              "20     around the    -1.009906\n",
              "175  south africa    -1.019293\n",
              "6     after being    -1.088850\n",
              "244       to kill    -1.197320\n",
              "188   the country    -1.225612\n",
              "260         up in    -1.273317"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-490eda1f-7917-4bf0-9255-d4f4d46d34d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>to help</td>\n",
              "      <td>-0.870909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>us and</td>\n",
              "      <td>-0.880771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>accused of</td>\n",
              "      <td>-0.952199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>people are</td>\n",
              "      <td>-0.974838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>around the</td>\n",
              "      <td>-1.009906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>south africa</td>\n",
              "      <td>-1.019293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>after being</td>\n",
              "      <td>-1.088850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>to kill</td>\n",
              "      <td>-1.197320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>the country</td>\n",
              "      <td>-1.225612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>up in</td>\n",
              "      <td>-1.273317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-490eda1f-7917-4bf0-9255-d4f4d46d34d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-490eda1f-7917-4bf0-9255-d4f4d46d34d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-490eda1f-7917-4bf0-9255-d4f4d46d34d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest - Bigram"
      ],
      "metadata": {
        "id": "JO3lBJAJAJ06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest - bigram\n",
        "\n",
        "nvectorize = TfidfVectorizer(min_df=0.01, max_df=0.95,ngram_range=(2,2))\n",
        "news_nvector = nvectorize.fit_transform(train_news_list)\n",
        "\n",
        "rfmodel = RandomForestClassifier(random_state=55)  #DEFINNG THE RANDOM FOREST MODEL\n",
        "rfmodel = rfmodel.fit(news_nvector, train_news[\"Label\"])\n",
        "test_news_list = []\n",
        "for row in range(0,len(test_news.index)):\n",
        "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:27]))\n",
        "ntest_vector = nvectorize.transform(test_news_list)\n",
        "\n",
        "rfpredictions = rfmodel.predict(ntest_vector)\n",
        "accuracyrf = accuracy_score(test_news['Label'], rfpredictions)\n",
        "print(\"Random forest with tfid and bigram\", accuracyrf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UVB9UMav6Xx",
        "outputId": "9f80d6f9-c324-4971-90fc-90a4f60837ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest with tfid and bigram 0.5372233400402414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "NM_iVHqh_vYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes\n",
        "\n",
        "nvectorize = TfidfVectorizer(min_df=0.05, max_df=0.8,ngram_range=(2,2)) #DEFINING THE NAIVE BAYS MODEL\n",
        "news_nvector = nvectorize.fit_transform(train_news_list)\n",
        "\n",
        "nbmodel = MultinomialNB(alpha=0.5)\n",
        "nbmodel = nbmodel.fit(news_nvector, train_news[\"Label\"])\n",
        "\n",
        "test_news_list = []\n",
        "for row in range(0,len(test_news.index)):\n",
        "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:27])) # CONVERT THE TESTING DATASET OF 27 COLUMNS INTO ONE ELEMENT IN THE LIST FOR EACH DAY\n",
        "ntest_vector = nvectorize.transform(test_news_list)\n"
      ],
      "metadata": {
        "id": "gaFrIw4DwEaw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbpredictions = nbmodel.predict(ntest_vector)\n",
        "nbaccuracy=accuracy_score(test_news['Label'], nbpredictions)\n",
        "print(\"Naive Bayes accuracy: \",nbaccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PRLfd0LwLFr",
        "outputId": "327592fa-5b0c-42e2-b1fb-0dc764abbb1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy:  0.5291750503018109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "GHpno5URBDa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boosting Classifier\n",
        "\n",
        "gbmodel = GradientBoostingClassifier(random_state=52)  # DEFINING THE GARDIANT BOOSTING MODEL\n",
        "gbmodel = gbmodel.fit(news_nvector, train_news[\"Label\"])\n",
        "test_news_list = []\n",
        "for row in range(0,len(test_news.index)):\n",
        "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:27]))\n",
        "ntest_vector = nvectorize.transform(test_news_list)\n",
        "\n",
        "gbpredictions = gbmodel.predict(ntest_vector.toarray())\n",
        "gbaccuracy = accuracy_score(test_news['Label'], gbpredictions)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\" CONFUSION MATRIX OF THE GRADIANT BOOSTING \", confusion_matrix(test_news['Label'], gbpredictions))\n",
        "\n",
        "\n",
        "print(\"Gradient Boosting accuracy: \",gbaccuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrRT2Xm5wTdx",
        "outputId": "89fad56b-8c3a-488c-c573-4fa3ac10a0f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CONFUSION MATRIX OF THE GRADIANT BOOSTING  [[ 92 148]\n",
            " [ 74 183]]\n",
            "Gradient Boosting accuracy:  0.5533199195171026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trigram"
      ],
      "metadata": {
        "id": "JkNnWkEOBK8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trigram\n",
        "\n",
        "n3vectorize = TfidfVectorizer(min_df=0.0004, max_df=0.115,ngram_range=(3,3)) # DEFINING THE TFID , TRIGRAM MODEL\n",
        "news_n3vector = n3vectorize.fit_transform(train_news_list)\n",
        "\n",
        "print(news_n3vector.shape)\n",
        "\n",
        "n3model = lr.fit(news_n3vector, train_news[\"Label\"])\n",
        "\n",
        "test_news_list = []\n",
        "for row in range(0,len(test_news.index)):\n",
        "    test_news_list.append(' '.join(str(x) for x in test_news.iloc[row,2:27])) # CONVERT THE TESTING DATASET OF 27 COLUMNS INTO ONE ELEMENT IN THE LIST FOR EACH DAY\n",
        "n3test_vector = n3vectorize.transform(test_news_list)\n",
        "n3predictions = n3model.predict(n3test_vector)\n",
        "\n",
        "pd.crosstab(test_news[\"Label\"], n3predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
        "\n",
        "accuracy3=accuracy_score(test_news['Label'], n3predictions)\n",
        "print(\"TRIGARAM ACCURACY\", accuracy3)\n",
        "\n",
        "n3words = n3vectorize.get_feature_names()\n",
        "n3coefficients = n3model.coef_.tolist()[0]\n",
        "n3coeffdf = pd.DataFrame({'Word' : n3words, \n",
        "                        'Coefficient' : n3coefficients})\n",
        "n3coeffdf = n3coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
        "print(\"trigram top ten word distibution\", n3coeffdf.head(10))\n",
        "print(\"trigram last ten word distibution\", n3coeffdf.tail(10))    # trigram model word distribution "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upbRYMgewZiC",
        "outputId": "db7eff2a-24f8-4710-cf88-384c221bb694"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1492, 569061)\n",
            "TRIGARAM ACCURACY 0.5171026156941649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trigram top ten word distibution                       Word  Coefficient\n",
            "509383           to the us     0.201353\n",
            "481307        the right to     0.170757\n",
            "322285   nobel peace prize     0.165954\n",
            "223934  human rights watch     0.159561\n",
            "491158         this is the     0.154585\n",
            "240342        in west bank     0.151582\n",
            "230935        in china the     0.139373\n",
            "518984         turn out to     0.137981\n",
            "239146     in the occupied     0.132398\n",
            "321584         no fly zone     0.127243\n",
            "trigram last ten word distibution                          Word  Coefficient\n",
            "183898      freedom of speech    -0.141552\n",
            "356524        osama bin laden    -0.142172\n",
            "371338  phone hacking scandal    -0.147765\n",
            "497344              to be the    -0.148226\n",
            "207018      has been arrested    -0.152082\n",
            "509742              to try to    -0.152849\n",
            "334728        of human rights    -0.170649\n",
            "416292             said to be    -0.191760\n",
            "48303        around the world    -0.195609\n",
            "238814         in the country    -0.223890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "YgblvpgUBRId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### sentiment analysis\n",
        "\n",
        "train_sentiment=train_news\n",
        "test_sentiment = test_news\n",
        "train_sentiment =train_sentiment.drop(['Date', 'Label'], axis=1)\n",
        "for column in train_sentiment:\n",
        "    train_sentiment[column]=train_sentiment[column].apply(analize_sentiment)  #converting the train headlines into polarity scores\n",
        "train_sentiment = train_sentiment+10  # removing negative co:efficient from the datset for better performance\n",
        "\n",
        "test_sentiment =test_sentiment.drop(['Date', 'Label'], axis=1)\n",
        "for column in test_sentiment:\n",
        "    test_sentiment[column]=test_sentiment[column].apply(analize_sentiment) # converting the test headlines into ploarity \n",
        "test_sentiment=test_sentiment+10 # removing negative co:efficient from the datset for better performance\n",
        "\n",
        "XGB_model= XGBClassifier()  # training the polarity score datset with DIJA \n",
        "gradiant=XGB_model.fit(train_sentiment, train_news['Label'])\n",
        "y_pred= gradiant.predict(test_sentiment)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(test_news['Label'], y_pred))\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Sentiment Accuracy\",accuracy_score(test_news['Label'], y_pred))\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"f1_score__\",f1_score(test_news['Label'], y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puckzmSfwhJn",
        "outputId": "46ccb61f-eb35-4114-e51a-3e1fa87d4b11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 75 165]\n",
            " [ 70 187]]\n",
            "Sentiment Accuracy 0.5271629778672032\n",
            "f1_score__ 0.5057056775644162\n"
          ]
        }
      ]
    }
  ]
}